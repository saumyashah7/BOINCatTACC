Below are the steps to submit a large number of Autodock-Vina jobs to BOINC@TACC from the Stampede2/LS5 systems. The scripts mentioned in these steps are provided in this directory.

Assumption: A directory of ligands is already available on Stampede2/LS5. The scripts in this directory are copied over to Stampede2/LS5 and the scripts have the execute permissions.

1) Run the script for extracting the tar files and the tar.gz files in the ligands directory. Copy the script into the ligands directory, add execute permissions, and run it.

./script_extract.sh 


2) After uncompressing the tar files, run the script to find all the PDQBT files in the directories of interest and list the paths to these files.
./find_pddqt_files_in_a_dir.sh <path-to-the-ligands-sub-directory>/AA <path-to-the-directory-in-which-the-jobs-should-be-prepared>/prepared_jobs/AA_pdbqt.txt



3) Copy the desired protein/receptor to the directory in which the jobs should be prepared.

cp 5r80_apo.pdbqt <path-to-the-directory-in-which-the-jobs-should-be-prepared>/.

Now this directory in which we are preparing the jobs should contain the following files:
$ ls 

5r80_apo.pdbqt 
find_pddqt_files_in_a_dir.sh 
AA_pdbqt.txt


4) Prepare BOINC@TACC work-units of at least 25 vina commands to compare the protein/receptor (5r80_apo.pdbqt) with the PDBQT files in the list AA_pdbqt.txt. 
To start with this, first prepare data directories. Copy sets of 25 ligands and the chosen receptor in separate directories, and prepare a compressed tar file of the directories.

./prepare_datadirecotries.sh  <path-to-the-directory-in-which-the-jobs-should-be-prepared>/prepared_jobs/AA_pdbqt.txt  <path-to-the-directory-in-which-the-jobs-should-be-prepared>/prepared_jobs/5r80_apo.pdbqt


5) Once the data directories are prepared as mentioned in step # 4 above, prepare the files with commands to run on the compressed data directories.

./vina_commands.sh <path-to-the-directory-in-which-the-jobs-should-be-prepared>/prepared_jobs 5r80_apo.pdbqt


6) Now prepare a directory from which the jobs will be submitted. 

mkdir -p test_scripts; cd ./test_scripts; 


7) Copy over the data*.tgz and *commands.sh files to the test_scripts directory. To organize the directory and stagger the submission of jobs, create 9 sub-directories in this directory.
mkdir data_1;
cp <path-to-the-directory-in-which-the-jobs-should-be-prepared>/data_1*.tgz ./data_1/.
cp <path-to-the-directory-in-which-the-jobs-should-be-prepared>/data_1*_mycommands.sh ./data_1/.

mkdir data_2;
cp <path-to-the-directory-in-which-the-jobs-should-be-prepared>/data_2*.tgz ./data_2/.
cp <path-to-the-directory-in-which-the-jobs-should-be-prepared>/data_2*_mycommands.sh ./data_2/.

mkdir data_3;
cp <path-to-the-directory-in-which-the-jobs-should-be-prepared>/data_3*.tgz ./data_3/.
cp <path-to-the-directory-in-which-the-jobs-should-be-prepared>/data_3*_mycommands.sh ./data_3/.

mkdir data_4;
cp <path-to-the-directory-in-which-the-jobs-should-be-prepared>/data_4*.tgz ./data_4/.
cp <path-to-the-directory-in-which-the-jobs-should-be-prepared>/data_4*_mycommands.sh ./data_4/.

mkdir data_5;
cp <path-to-the-directory-in-which-the-jobs-should-be-prepared>/data_5*.tgz ./data_5/.
cp <path-to-the-directory-in-which-the-jobs-should-be-prepared>/data_5*_mycommands.sh ./data_5/.

mkdir data_6;
cp <path-to-the-directory-in-which-the-jobs-should-be-prepared>/data_6*.tgz ./data_6/.
cp <path-to-the-directory-in-which-the-jobs-should-be-prepared>/data_6*_mycommands.sh ./data_6/.

mkdir data_7;
cp <path-to-the-directory-in-which-the-jobs-should-be-prepared>/data_7*.tgz ./data_7/.
cp <path-to-the-directory-in-which-the-jobs-should-be-prepared>/data_7*_mycommands.sh ./data_7/.

mkdir data_8;
cp <path-to-the-directory-in-which-the-jobs-should-be-prepared>/data_8*.tgz ./data_8/.
cp <path-to-the-directory-in-which-the-jobs-should-be-prepared>/data_8*_mycommands.sh ./data_8/.

mkdir data_9;
cp <path-to-the-directory-in-which-the-jobs-should-be-prepared>/data_9*.tgz ./data_9/.
cp <path-to-the-directory-in-which-the-jobs-should-be-prepared>/data_9*_mycommands.sh ./data_9/.


8) Copy the wrapper script and the adv_automate_boinc_submit.sh script to the test_scripts directory. Run this script 9 times, providing the path to one of data_* directories each time.

./wrapper_script.sh <path-to-test-scripts-directory>/test_scripts/data_1

./wrapper_script.sh <path-to-test-scripts-directory>/test_scripts/data_2

./wrapper_script.sh <path-to-test-scripts-directory>/test_scripts/data_3

./wrapper_script.sh <path-to-test-scripts-directory>/test_scripts/data_4

./wrapper_script.sh <path-to-test-scripts-directory>/test_scripts/data_5

./wrapper_script.sh <path-to-test-scripts-directory>/test_scripts/data_6

./wrapper_script.sh <path-to-test-scripts-directory>/test_scripts/data_7

./wrapper_script.sh <path-to-test-scripts-directory>/test_scripts/data_8

./wrapper_script.sh <path-to-test-scripts-directory>/test_scripts/data_9


9) The results will be sent to the email provided in the adv_automate_boinc_submit.sh file. A Google script has been set-up to copy the results sent in the attachment to a Google drive folder.
Additionally, results are also being copied to a JetStream VM. The results (out_*.pdbqt files) would need to be transferred to Staampede2/LS5.



10) Once the output files are transferred to Stampede2/LS5, run the post-processing script. This script reads the out_*.pdbqt files and gets the scores for each receptor and ligand combination.
The scores are sorted and writted to a CSV file.

The script can be run as follows from the directory containing the out_*.pdbqt files: 

./process_vina_output.sh <ligand-name>

For example:
./process_vina_output.sh 5r80_apo.pdbqt



Note: The steps above would need to be repeated for each sub-directory of ligands. You can delete the *.tgz and *_mycommands.sh files from the prepared_datadirectories folder after processing each sub-directory.
You can create a directory with the ligand sub-directory name (e.g., AA and AB) in the test_scripts directory. After a batch of jobs is submitted, move the data_* sub-directories in the test_scripts directory into the sub-directory with the ligands name. 
Repeat steps 2-10 for the next ligand sub-directory.

Examples of some useful commands for navigating the large directories:
1) Find files created on a particular date
find . -type f -mtime $(( ( $(date +%s) - $(date -d '2020-04-12' +%s) ) / 60 / 60 / 24 - 1 ))

2) Check disk-space usage on Lustre filessystems - this command is faster than "du -sh":
lfs quota -h -u username directory-path

Remember that once you have several thousand files in a directory, "ls -ltr"/"ls" will be slugglish. Split the directory into multiple sub-directories if this is the case.
Also, using "/bin/ls" instead of "ls"/"ls -ltr" will give quicker turnaround time.
